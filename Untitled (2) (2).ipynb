{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2038430e-3112-4bbf-8e93-0a82c38a273a",
   "metadata": {},
   "source": [
    "MODEL-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "927f6679-04b1-48f8-9848-bd5012154166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0c578d-42a3-4605-b1db-9e9308db6c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filename', 'length', 'chroma_stft_mean', 'chroma_stft_var', 'rms_mean',\n",
      "       'rms_var', 'spectral_centroid_mean', 'spectral_centroid_var',\n",
      "       'spectral_bandwidth_mean', 'spectral_bandwidth_var', 'rolloff_mean',\n",
      "       'rolloff_var', 'zero_crossing_rate_mean', 'zero_crossing_rate_var',\n",
      "       'harmony_mean', 'harmony_var', 'perceptr_mean', 'perceptr_var', 'tempo',\n",
      "       'mfcc1_mean', 'mfcc1_var', 'mfcc2_mean', 'mfcc2_var', 'mfcc3_mean',\n",
      "       'mfcc3_var', 'mfcc4_mean', 'mfcc4_var', 'mfcc5_mean', 'mfcc5_var',\n",
      "       'mfcc6_mean', 'mfcc6_var', 'mfcc7_mean', 'mfcc7_var', 'mfcc8_mean',\n",
      "       'mfcc8_var', 'mfcc9_mean', 'mfcc9_var', 'mfcc10_mean', 'mfcc10_var',\n",
      "       'mfcc11_mean', 'mfcc11_var', 'mfcc12_mean', 'mfcc12_var', 'mfcc13_mean',\n",
      "       'mfcc13_var', 'mfcc14_mean', 'mfcc14_var', 'mfcc15_mean', 'mfcc15_var',\n",
      "       'mfcc16_mean', 'mfcc16_var', 'mfcc17_mean', 'mfcc17_var', 'mfcc18_mean',\n",
      "       'mfcc18_var', 'mfcc19_mean', 'mfcc19_var', 'mfcc20_mean', 'mfcc20_var',\n",
      "       'label'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>...</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>...</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>...</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>...</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0  blues.00000.wav  661794          0.350088         0.088757  0.130228   \n",
       "1  blues.00001.wav  661794          0.340914         0.094980  0.095948   \n",
       "2  blues.00002.wav  661794          0.363637         0.085275  0.175570   \n",
       "3  blues.00003.wav  661794          0.404785         0.093999  0.141093   \n",
       "4  blues.00004.wav  661794          0.308526         0.087841  0.091529   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0  0.002827             1784.165850          129774.064525   \n",
       "1  0.002373             1530.176679          375850.073649   \n",
       "2  0.002746             1552.811865          156467.643368   \n",
       "3  0.006346             1070.106615          184355.942417   \n",
       "4  0.002303             1835.004266          343399.939274   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0              2002.449060            85882.761315  ...   52.420910   \n",
       "1              2039.036516           213843.755497  ...   55.356403   \n",
       "2              1747.702312            76254.192257  ...   40.598766   \n",
       "3              1596.412872           166441.494769  ...   44.427753   \n",
       "4              1748.172116            88445.209036  ...   86.099236   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0    -1.690215   36.524071    -0.408979   41.597103    -2.303523   55.062923   \n",
       "1    -0.731125   60.314529     0.295073   48.120598    -0.283518   51.106190   \n",
       "2    -7.729093   47.639427    -1.816407   52.382141    -3.439720   46.639660   \n",
       "3    -3.319597   50.206673     0.636965   37.319130    -0.619121   37.259739   \n",
       "4    -5.454034   75.269707    -0.916874   53.613918    -4.404827   62.910812   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0     1.221291   46.936035  blues  \n",
       "1     0.531217   45.786282  blues  \n",
       "2    -2.231258   30.573025  blues  \n",
       "3    -3.407448   31.949339  blues  \n",
       "4   -11.703234   55.195160  blues  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Excel file\n",
    "df = pd.read_csv(r\"C:\\Users\\menda\\Downloads\\DNN-music _dataset\\Data\\features_30_sec.csv\")\n",
    "\n",
    "# Display basic info\n",
    "print(df.columns)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af74160-062b-49d6-8dc5-cc75b6d94317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the dataset (CSV)\n",
    "df = pd.read_csv(r\"C:\\Users\\menda\\Downloads\\DNN-music _dataset\\Data\\features_30_sec.csv\")\n",
    "\n",
    "# Drop non-feature columns\n",
    "X = df.drop(['filename', 'length', 'label'], axis=1)\n",
    "\n",
    "# Encode the labels (genres)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['label'])\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "561eb377-e950-4237-9f30-831a6245b8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3263d2-98f3-444d-9a56-fadf302500b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class FCNN:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, learning_rate=0.01):\n",
    "        self.lr = learning_rate\n",
    "        self.params = {}\n",
    "        self.init_weights(input_size, hidden_sizes, output_size)\n",
    "        \n",
    "    def init_weights(self, input_size, hidden_sizes, output_size):\n",
    "        layers = [input_size] + hidden_sizes + [output_size]\n",
    "        for i in range(len(layers) - 1):\n",
    "            limit = np.sqrt(6 / (layers[i] + layers[i+1]))\n",
    "            self.params[f\"W{i+1}\"] = np.random.uniform(-limit, limit, (layers[i], layers[i+1]))\n",
    "\n",
    "            self.params[f\"b{i+1}\"] = np.zeros((1, layers[i+1]))\n",
    "    \n",
    "    def relu(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "\n",
    "    def relu_deriv(self, Z):\n",
    "        return (Z > 0).astype(float)\n",
    "\n",
    "    def softmax(self, Z):\n",
    "        expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "        return expZ / expZ.sum(axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.cache = {'A0': X}\n",
    "        A = X\n",
    "        L = len(self.params) // 2\n",
    "        for i in range(1, L):\n",
    "            Z = A @ self.params[f\"W{i}\"] + self.params[f\"b{i}\"]\n",
    "            A = self.relu(Z)\n",
    "            self.cache[f\"Z{i}\"], self.cache[f\"A{i}\"] = Z, A\n",
    "        ZL = A @ self.params[f\"W{L}\"] + self.params[f\"b{L}\"]\n",
    "        AL = self.softmax(ZL)\n",
    "        self.cache[f\"Z{L}\"], self.cache[f\"A{L}\"] = ZL, AL\n",
    "        return AL\n",
    "\n",
    "    def compute_loss(self, Y_hat, Y):\n",
    "        m = Y.shape[0]\n",
    "        log_likelihood = -np.log(Y_hat[range(m), Y])\n",
    "        return np.sum(log_likelihood) / m\n",
    "\n",
    "    def backward(self, Y):\n",
    "        grads = {}\n",
    "        m = Y.shape[0]\n",
    "        L = len(self.params) // 2\n",
    "        Y_hat = self.cache[f\"A{L}\"]\n",
    "        dZ = Y_hat\n",
    "        dZ[range(m), Y] -= 1\n",
    "        dZ /= m\n",
    "        for i in reversed(range(1, L+1)):\n",
    "            A_prev = self.cache[f\"A{i-1}\"]\n",
    "            grads[f\"dW{i}\"] = A_prev.T @ dZ\n",
    "            grads[f\"db{i}\"] = np.sum(dZ, axis=0, keepdims=True)\n",
    "            if i > 1:\n",
    "                dA_prev = dZ @ self.params[f\"W{i}\"].T\n",
    "                dZ = dA_prev * self.relu_deriv(self.cache[f\"Z{i-1}\"])\n",
    "        return grads\n",
    "\n",
    "    def update_params(self, grads):\n",
    "        L = len(self.params) // 2\n",
    "        for i in range(1, L+1):\n",
    "            self.params[f\"W{i}\"] -= self.lr * grads[f\"dW{i}\"]\n",
    "            self.params[f\"b{i}\"] -= self.lr * grads[f\"db{i}\"]\n",
    "\n",
    "    def predict(self, X):\n",
    "        Y_hat = self.forward(X)\n",
    "        return np.argmax(Y_hat, axis=1)\n",
    "\n",
    "    def fit(self, X, Y, epochs=100):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            Y_hat = self.forward(X)\n",
    "            loss = self.compute_loss(Y_hat, Y)\n",
    "            grads = self.backward(Y)\n",
    "            self.update_params(grads)\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch} - Loss: {loss:.4f}\")\n",
    "            losses.append(loss)\n",
    "        return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74edb56-e34e-484a-843b-f9fbd9991532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 2.3323\n",
      "Epoch 10 - Loss: 2.2554\n",
      "Epoch 20 - Loss: 2.1908\n",
      "Epoch 30 - Loss: 2.1319\n",
      "Epoch 40 - Loss: 2.0775\n",
      "Epoch 50 - Loss: 2.0259\n",
      "Epoch 60 - Loss: 1.9765\n",
      "Epoch 70 - Loss: 1.9291\n",
      "Epoch 80 - Loss: 1.8839\n",
      "Epoch 90 - Loss: 1.8404\n",
      "Epoch 100 - Loss: 1.7984\n",
      "Epoch 110 - Loss: 1.7579\n",
      "Epoch 120 - Loss: 1.7187\n",
      "Epoch 130 - Loss: 1.6812\n",
      "Epoch 140 - Loss: 1.6454\n",
      "Epoch 150 - Loss: 1.6111\n",
      "Epoch 160 - Loss: 1.5781\n",
      "Epoch 170 - Loss: 1.5465\n",
      "Epoch 180 - Loss: 1.5163\n",
      "Epoch 190 - Loss: 1.4874\n",
      "Epoch 200 - Loss: 1.4597\n",
      "Epoch 210 - Loss: 1.4331\n",
      "Epoch 220 - Loss: 1.4074\n",
      "Epoch 230 - Loss: 1.3826\n",
      "Epoch 240 - Loss: 1.3587\n",
      "Epoch 250 - Loss: 1.3356\n",
      "Epoch 260 - Loss: 1.3134\n",
      "Epoch 270 - Loss: 1.2920\n",
      "Epoch 280 - Loss: 1.2712\n",
      "Epoch 290 - Loss: 1.2510\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [256,128, 64]\n",
    "output_size = len(np.unique(y_train))\n",
    "\n",
    "model = FCNN(input_size, hidden_sizes, output_size, learning_rate=0.01)\n",
    "fcnn_history = model.fit(X_train, y_train, epochs=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d07cc9-e0ac-40d7-9e7b-eaa671f6a229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae418d2-e78c-4f52-bf54-14d5b32f782b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fcnn_history)\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f969b-b59f-46db-9312-bf75276e9262",
   "metadata": {},
   "source": [
    "model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b8c0dd7-6be6-43cb-96ab-c375bded6d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 999 images across 10 genres.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "image_dir = r\"C:\\Users\\menda\\Downloads\\DNN-music _dataset\\Data\\images_original\"\n",
    "img_size = (128, 128)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for genre in os.listdir(image_dir):\n",
    "    genre_path = os.path.join(image_dir, genre)\n",
    "    if not os.path.isdir(genre_path):\n",
    "        continue\n",
    "\n",
    "    for img_file in os.listdir(genre_path):\n",
    "        if not img_file.endswith(\".png\"):\n",
    "            continue\n",
    "        img_path = os.path.join(genre_path, img_file)\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = img.resize(img_size)\n",
    "            X.append(np.array(img))\n",
    "            y.append(genre)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "X = np.array(X) / 255.0  # Normalize\n",
    "y = np.array(y)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "print(f\"Loaded {len(X)} images across {len(le.classes_)} genres.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0da053f3-5ce3-43bb-ba70-d2ef22df54e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\menda\\conda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.0973 - loss: 2.4226 - val_accuracy: 0.2350 - val_loss: 2.2241\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - accuracy: 0.2214 - loss: 2.1379 - val_accuracy: 0.3300 - val_loss: 1.9067\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.3230 - loss: 1.8322 - val_accuracy: 0.3700 - val_loss: 1.7611\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - accuracy: 0.4074 - loss: 1.6300 - val_accuracy: 0.3800 - val_loss: 1.7249\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.4406 - loss: 1.5275 - val_accuracy: 0.4750 - val_loss: 1.6008\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.5469 - loss: 1.3278 - val_accuracy: 0.5100 - val_loss: 1.4958\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.6054 - loss: 1.1441 - val_accuracy: 0.4750 - val_loss: 1.4612\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.6708 - loss: 1.0205 - val_accuracy: 0.5100 - val_loss: 1.3639\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.7250 - loss: 0.8588 - val_accuracy: 0.5850 - val_loss: 1.3643\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.7503 - loss: 0.7609 - val_accuracy: 0.5300 - val_loss: 1.3341\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - accuracy: 0.7717 - loss: 0.6485 - val_accuracy: 0.5600 - val_loss: 1.2571\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.8411 - loss: 0.5293 - val_accuracy: 0.5750 - val_loss: 1.5061\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.8971 - loss: 0.3243 - val_accuracy: 0.5500 - val_loss: 1.5701\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.8805 - loss: 0.3371 - val_accuracy: 0.5800 - val_loss: 1.7840\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.9266 - loss: 0.2362 - val_accuracy: 0.5700 - val_loss: 1.7389\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.9396 - loss: 0.1903 - val_accuracy: 0.5900 - val_loss: 1.7050\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.9792 - loss: 0.0974 - val_accuracy: 0.6300 - val_loss: 1.9782\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.9836 - loss: 0.0821 - val_accuracy: 0.5800 - val_loss: 2.1314\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - accuracy: 0.9875 - loss: 0.0515 - val_accuracy: 0.5100 - val_loss: 2.4570\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - accuracy: 0.9832 - loss: 0.0769 - val_accuracy: 0.5550 - val_loss: 2.2747\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.9961 - loss: 0.0305 - val_accuracy: 0.5050 - val_loss: 2.6304\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.9900 - loss: 0.0441 - val_accuracy: 0.5700 - val_loss: 2.2494\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.9970 - loss: 0.0187 - val_accuracy: 0.5400 - val_loss: 2.4095\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.9930 - loss: 0.0394 - val_accuracy: 0.5750 - val_loss: 2.2745\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.9944 - loss: 0.0231 - val_accuracy: 0.5300 - val_loss: 2.7346\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - accuracy: 0.9937 - loss: 0.0310 - val_accuracy: 0.6050 - val_loss: 2.4382\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.9966 - loss: 0.0126 - val_accuracy: 0.6000 - val_loss: 2.3668\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - accuracy: 0.9974 - loss: 0.0197 - val_accuracy: 0.5850 - val_loss: 2.3379\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.9992 - loss: 0.0092 - val_accuracy: 0.5850 - val_loss: 2.5764\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.9870 - loss: 0.0547 - val_accuracy: 0.5350 - val_loss: 2.1928\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.9727 - loss: 0.0979 - val_accuracy: 0.5150 - val_loss: 2.5656\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.9690 - loss: 0.0867 - val_accuracy: 0.5500 - val_loss: 2.3238\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.9688 - loss: 0.1288 - val_accuracy: 0.5650 - val_loss: 2.4000\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - accuracy: 0.9955 - loss: 0.0208 - val_accuracy: 0.5850 - val_loss: 2.4263\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.9997 - loss: 0.0080 - val_accuracy: 0.5750 - val_loss: 2.6536\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - accuracy: 0.9996 - loss: 0.0049 - val_accuracy: 0.6250 - val_loss: 2.5984\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.9986 - loss: 0.0117 - val_accuracy: 0.6050 - val_loss: 2.6794\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.9978 - loss: 0.0076 - val_accuracy: 0.5850 - val_loss: 2.9990\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.9966 - loss: 0.0242 - val_accuracy: 0.6050 - val_loss: 2.5619\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.9998 - loss: 0.0027 - val_accuracy: 0.6050 - val_loss: 2.7591\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.9995 - loss: 0.0042 - val_accuracy: 0.6150 - val_loss: 2.6913\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.6000 - val_loss: 2.7655\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - accuracy: 0.9999 - loss: 0.0019 - val_accuracy: 0.6000 - val_loss: 2.7448\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.9986 - loss: 0.0067 - val_accuracy: 0.6050 - val_loss: 2.7544\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.9999 - loss: 0.0040 - val_accuracy: 0.6050 - val_loss: 2.7810\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 0.6050 - val_loss: 2.7681\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 0.6050 - val_loss: 2.7615\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.9976 - loss: 0.0047 - val_accuracy: 0.6200 - val_loss: 2.7846\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.5950 - val_loss: 2.8947\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.9994 - loss: 0.0066 - val_accuracy: 0.6150 - val_loss: 2.7521\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# CNN architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "cnn_history = model.fit(X_train, y_train_cat, epochs=50, batch_size=32, validation_data=(X_test, y_test_cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "000fa802-ba66-468e-983e-7e0cca31d016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6085 - loss: 2.8675\n",
      "Test Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test_cat)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a1c65-ed75-4411-acb4-2568890fd10a",
   "metadata": {},
   "source": [
    "model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbe698b5-75cd-4531-b180-c6321e2f1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(r\"C:\\Users\\menda\\Downloads\\DNN-music _dataset\\Data\\features_30_sec.csv\")\n",
    "\n",
    "# Extract MFCCs (means and vars)\n",
    "mfcc_cols = []\n",
    "for i in range(1, 21):\n",
    "    mfcc_cols.append(f'mfcc{i}_mean')\n",
    "    mfcc_cols.append(f'mfcc{i}_var')\n",
    "\n",
    "X = df[mfcc_cols].values  # shape: (n_samples, 40)\n",
    "y = df['label'].values\n",
    "\n",
    "# Reshape to (samples, timesteps=20, features=2)\n",
    "X_seq = X.reshape(X.shape[0], 20, 2)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_cat = to_categorical(y_encoded)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_cat, test_size=0.2, random_state=42, stratify=y_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eac9514-9c7b-49fe-85fe-04bec7359864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\menda\\conda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.1485 - loss: 2.7405 - val_accuracy: 0.1250 - val_loss: 2.2930\n",
      "Epoch 2/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2367 - loss: 2.1940 - val_accuracy: 0.1700 - val_loss: 2.2629\n",
      "Epoch 3/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3011 - loss: 2.0362 - val_accuracy: 0.1650 - val_loss: 2.2233\n",
      "Epoch 4/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3425 - loss: 1.8887 - val_accuracy: 0.2250 - val_loss: 2.1523\n",
      "Epoch 5/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3323 - loss: 1.8601 - val_accuracy: 0.3200 - val_loss: 2.0559\n",
      "Epoch 6/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3694 - loss: 1.7709 - val_accuracy: 0.3500 - val_loss: 1.9728\n",
      "Epoch 7/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3605 - loss: 1.7607 - val_accuracy: 0.2800 - val_loss: 1.9417\n",
      "Epoch 8/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4095 - loss: 1.6155 - val_accuracy: 0.3600 - val_loss: 1.8430\n",
      "Epoch 9/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4223 - loss: 1.6166 - val_accuracy: 0.3450 - val_loss: 1.8419\n",
      "Epoch 10/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4061 - loss: 1.6108 - val_accuracy: 0.3550 - val_loss: 1.7679\n",
      "Epoch 11/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4288 - loss: 1.5579 - val_accuracy: 0.4550 - val_loss: 1.6270\n",
      "Epoch 12/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4222 - loss: 1.5482 - val_accuracy: 0.4200 - val_loss: 1.6523\n",
      "Epoch 13/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4474 - loss: 1.5317 - val_accuracy: 0.4250 - val_loss: 1.5873\n",
      "Epoch 14/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4855 - loss: 1.4404 - val_accuracy: 0.4300 - val_loss: 1.6100\n",
      "Epoch 15/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4716 - loss: 1.4860 - val_accuracy: 0.4850 - val_loss: 1.4830\n",
      "Epoch 16/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4486 - loss: 1.5005 - val_accuracy: 0.4500 - val_loss: 1.5054\n",
      "Epoch 17/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4829 - loss: 1.5020 - val_accuracy: 0.4350 - val_loss: 1.5002\n",
      "Epoch 18/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4354 - loss: 1.5374 - val_accuracy: 0.4650 - val_loss: 1.4429\n",
      "Epoch 19/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5108 - loss: 1.3923 - val_accuracy: 0.4900 - val_loss: 1.4324\n",
      "Epoch 20/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4728 - loss: 1.4120 - val_accuracy: 0.5300 - val_loss: 1.3688\n",
      "Epoch 21/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5274 - loss: 1.3066 - val_accuracy: 0.5150 - val_loss: 1.3766\n",
      "Epoch 22/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5134 - loss: 1.3212 - val_accuracy: 0.5050 - val_loss: 1.4162\n",
      "Epoch 23/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5307 - loss: 1.3142 - val_accuracy: 0.5450 - val_loss: 1.3486\n",
      "Epoch 24/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5095 - loss: 1.3852 - val_accuracy: 0.5000 - val_loss: 1.4427\n",
      "Epoch 25/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5253 - loss: 1.2961 - val_accuracy: 0.5400 - val_loss: 1.3456\n",
      "Epoch 26/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5387 - loss: 1.3044 - val_accuracy: 0.5000 - val_loss: 1.5703\n",
      "Epoch 27/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5213 - loss: 1.2800 - val_accuracy: 0.5550 - val_loss: 1.3886\n",
      "Epoch 28/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5594 - loss: 1.2636 - val_accuracy: 0.5200 - val_loss: 1.4134\n",
      "Epoch 29/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5345 - loss: 1.3072 - val_accuracy: 0.5300 - val_loss: 1.3464\n",
      "Epoch 30/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5263 - loss: 1.2618 - val_accuracy: 0.5000 - val_loss: 1.4020\n",
      "Epoch 31/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5698 - loss: 1.2468 - val_accuracy: 0.5500 - val_loss: 1.3223\n",
      "Epoch 32/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5644 - loss: 1.2486 - val_accuracy: 0.5250 - val_loss: 1.4401\n",
      "Epoch 33/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5560 - loss: 1.2220 - val_accuracy: 0.5050 - val_loss: 1.3814\n",
      "Epoch 34/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5547 - loss: 1.2459 - val_accuracy: 0.5650 - val_loss: 1.3253\n",
      "Epoch 35/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5677 - loss: 1.2578 - val_accuracy: 0.5250 - val_loss: 1.4354\n",
      "Epoch 36/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5116 - loss: 1.2413 - val_accuracy: 0.5650 - val_loss: 1.4171\n",
      "Epoch 37/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5776 - loss: 1.2037 - val_accuracy: 0.5000 - val_loss: 1.5591\n",
      "Epoch 38/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5618 - loss: 1.2224 - val_accuracy: 0.4850 - val_loss: 1.5594\n",
      "Epoch 39/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5772 - loss: 1.1885 - val_accuracy: 0.5350 - val_loss: 1.3437\n",
      "Epoch 40/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5472 - loss: 1.1978 - val_accuracy: 0.5650 - val_loss: 1.2846\n",
      "Epoch 41/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6446 - loss: 1.0920 - val_accuracy: 0.5500 - val_loss: 1.3015\n",
      "Epoch 42/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6007 - loss: 1.1480 - val_accuracy: 0.5400 - val_loss: 1.3106\n",
      "Epoch 43/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5868 - loss: 1.1634 - val_accuracy: 0.5250 - val_loss: 1.4772\n",
      "Epoch 44/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5835 - loss: 1.1700 - val_accuracy: 0.5350 - val_loss: 1.3452\n",
      "Epoch 45/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5687 - loss: 1.2242 - val_accuracy: 0.5050 - val_loss: 1.4632\n",
      "Epoch 46/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5811 - loss: 1.1622 - val_accuracy: 0.5600 - val_loss: 1.3839\n",
      "Epoch 47/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5848 - loss: 1.1975 - val_accuracy: 0.5650 - val_loss: 1.3183\n",
      "Epoch 48/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6068 - loss: 1.1508 - val_accuracy: 0.5300 - val_loss: 1.3860\n",
      "Epoch 49/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6474 - loss: 1.0591 - val_accuracy: 0.6050 - val_loss: 1.2650\n",
      "Epoch 50/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6045 - loss: 1.0673 - val_accuracy: 0.5650 - val_loss: 1.3535\n",
      "Epoch 51/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5973 - loss: 1.1246 - val_accuracy: 0.5250 - val_loss: 1.3628\n",
      "Epoch 52/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6159 - loss: 1.0685 - val_accuracy: 0.5300 - val_loss: 1.4488\n",
      "Epoch 53/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5881 - loss: 1.1151 - val_accuracy: 0.5600 - val_loss: 1.4500\n",
      "Epoch 54/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6119 - loss: 1.0939 - val_accuracy: 0.5950 - val_loss: 1.2776\n",
      "Epoch 55/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6108 - loss: 1.0858 - val_accuracy: 0.5650 - val_loss: 1.2848\n",
      "Epoch 56/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6624 - loss: 1.0151 - val_accuracy: 0.5950 - val_loss: 1.3250\n",
      "Epoch 57/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5982 - loss: 1.0465 - val_accuracy: 0.5750 - val_loss: 1.3268\n",
      "Epoch 58/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6307 - loss: 1.0575 - val_accuracy: 0.5350 - val_loss: 1.4016\n",
      "Epoch 59/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6510 - loss: 1.0353 - val_accuracy: 0.5500 - val_loss: 1.5219\n",
      "Epoch 60/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6402 - loss: 1.0133 - val_accuracy: 0.5500 - val_loss: 1.3200\n",
      "Epoch 61/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5922 - loss: 1.0715 - val_accuracy: 0.5400 - val_loss: 1.4777\n",
      "Epoch 62/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6014 - loss: 1.1531 - val_accuracy: 0.5300 - val_loss: 1.3026\n",
      "Epoch 63/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6403 - loss: 1.0675 - val_accuracy: 0.5300 - val_loss: 1.4397\n",
      "Epoch 64/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6529 - loss: 0.9960 - val_accuracy: 0.5400 - val_loss: 1.3608\n",
      "Epoch 65/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6063 - loss: 1.0583 - val_accuracy: 0.5800 - val_loss: 1.3101\n",
      "Epoch 66/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6631 - loss: 0.9856 - val_accuracy: 0.5450 - val_loss: 1.4034\n",
      "Epoch 67/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6580 - loss: 0.9703 - val_accuracy: 0.5900 - val_loss: 1.3156\n",
      "Epoch 68/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6200 - loss: 1.0523 - val_accuracy: 0.5600 - val_loss: 1.3623\n",
      "Epoch 69/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6428 - loss: 0.9798 - val_accuracy: 0.5300 - val_loss: 1.3603\n",
      "Epoch 70/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6630 - loss: 0.9595 - val_accuracy: 0.5750 - val_loss: 1.2861\n",
      "Epoch 71/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6360 - loss: 0.9831 - val_accuracy: 0.5550 - val_loss: 1.3102\n",
      "Epoch 72/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6440 - loss: 0.9805 - val_accuracy: 0.5700 - val_loss: 1.2835\n",
      "Epoch 73/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6769 - loss: 0.9104 - val_accuracy: 0.5250 - val_loss: 1.3401\n",
      "Epoch 74/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6471 - loss: 0.9640 - val_accuracy: 0.5600 - val_loss: 1.3762\n",
      "Epoch 75/75\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6654 - loss: 0.9549 - val_accuracy: 0.5900 - val_loss: 1.4424\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(20, 2)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    LSTM(64),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "lstm_history = model.fit(X_train, y_train, epochs=75, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16d3190e-8092-4e95-916c-622ed978976f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5795 - loss: 1.4130 \n",
      "LSTM Test Accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"LSTM Test Accuracy: {test_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f981e-ef0c-4f28-bb35-0d47143c15f8",
   "metadata": {},
   "source": [
    "model-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c51ab4fd-8feb-462f-a8d6-1a06f70b7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_cols = []\n",
    "for i in range(1, 21):\n",
    "    mfcc_cols.append(f'mfcc{i}_mean')\n",
    "    mfcc_cols.append(f'mfcc{i}_var')\n",
    "\n",
    "X = df[mfcc_cols].values\n",
    "X_seq = X.reshape(X.shape[0], 20, 2)  # Shape: (samples, timesteps=20, features=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bac2a05-5782-4120-aa75-a413411b7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(df['label'])\n",
    "y_cat = to_categorical(y_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_cat, test_size=0.2, random_state=42, stratify=y_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6713c54f-aae7-42e9-9f4f-c3dbc4d002e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\menda\\conda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.1154 - loss: 2.2971 - val_accuracy: 0.1000 - val_loss: 2.2985\n",
      "Epoch 2/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2241 - loss: 2.2060 - val_accuracy: 0.1900 - val_loss: 2.1384\n",
      "Epoch 3/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2538 - loss: 2.0858 - val_accuracy: 0.3350 - val_loss: 1.9375\n",
      "Epoch 4/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3151 - loss: 1.9143 - val_accuracy: 0.3000 - val_loss: 1.8387\n",
      "Epoch 5/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3307 - loss: 1.8145 - val_accuracy: 0.2900 - val_loss: 1.8567\n",
      "Epoch 6/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3387 - loss: 1.7171 - val_accuracy: 0.3000 - val_loss: 1.7685\n",
      "Epoch 7/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3486 - loss: 1.6823 - val_accuracy: 0.3900 - val_loss: 1.5697\n",
      "Epoch 8/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3724 - loss: 1.6310 - val_accuracy: 0.4450 - val_loss: 1.5479\n",
      "Epoch 9/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4088 - loss: 1.5563 - val_accuracy: 0.4350 - val_loss: 1.4585\n",
      "Epoch 10/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4059 - loss: 1.5659 - val_accuracy: 0.4600 - val_loss: 1.4546\n",
      "Epoch 11/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4474 - loss: 1.4929 - val_accuracy: 0.4400 - val_loss: 1.4998\n",
      "Epoch 12/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4696 - loss: 1.4537 - val_accuracy: 0.4300 - val_loss: 1.4388\n",
      "Epoch 13/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4522 - loss: 1.5257 - val_accuracy: 0.4550 - val_loss: 1.4437\n",
      "Epoch 14/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4617 - loss: 1.3828 - val_accuracy: 0.4250 - val_loss: 1.4819\n",
      "Epoch 15/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4899 - loss: 1.4767 - val_accuracy: 0.5450 - val_loss: 1.3454\n",
      "Epoch 16/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4544 - loss: 1.4404 - val_accuracy: 0.5000 - val_loss: 1.3562\n",
      "Epoch 17/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5262 - loss: 1.2908 - val_accuracy: 0.5150 - val_loss: 1.3274\n",
      "Epoch 18/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4937 - loss: 1.3087 - val_accuracy: 0.5850 - val_loss: 1.2738\n",
      "Epoch 19/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5268 - loss: 1.2882 - val_accuracy: 0.5750 - val_loss: 1.2671\n",
      "Epoch 20/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5179 - loss: 1.3264 - val_accuracy: 0.5800 - val_loss: 1.2373\n",
      "Epoch 21/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5062 - loss: 1.3504 - val_accuracy: 0.6000 - val_loss: 1.1983\n",
      "Epoch 22/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5244 - loss: 1.2426 - val_accuracy: 0.5800 - val_loss: 1.2021\n",
      "Epoch 23/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5503 - loss: 1.2528 - val_accuracy: 0.6050 - val_loss: 1.1843\n",
      "Epoch 24/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5287 - loss: 1.2132 - val_accuracy: 0.6100 - val_loss: 1.1944\n",
      "Epoch 25/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5420 - loss: 1.2048 - val_accuracy: 0.5850 - val_loss: 1.2103\n",
      "Epoch 26/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5393 - loss: 1.2092 - val_accuracy: 0.5800 - val_loss: 1.1838\n",
      "Epoch 27/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5688 - loss: 1.2121 - val_accuracy: 0.5450 - val_loss: 1.2764\n",
      "Epoch 28/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5436 - loss: 1.2133 - val_accuracy: 0.6250 - val_loss: 1.0724\n",
      "Epoch 29/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5528 - loss: 1.1976 - val_accuracy: 0.5950 - val_loss: 1.1051\n",
      "Epoch 30/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5701 - loss: 1.1762 - val_accuracy: 0.6250 - val_loss: 1.0351\n",
      "Epoch 31/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5463 - loss: 1.1985 - val_accuracy: 0.6250 - val_loss: 1.0823\n",
      "Epoch 32/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5460 - loss: 1.2051 - val_accuracy: 0.6100 - val_loss: 1.0682\n",
      "Epoch 33/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5549 - loss: 1.1644 - val_accuracy: 0.6250 - val_loss: 1.0837\n",
      "Epoch 34/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6175 - loss: 1.0817 - val_accuracy: 0.6050 - val_loss: 1.1308\n",
      "Epoch 35/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5684 - loss: 1.1547 - val_accuracy: 0.6150 - val_loss: 1.1164\n",
      "Epoch 36/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5810 - loss: 1.2186 - val_accuracy: 0.6450 - val_loss: 1.1245\n",
      "Epoch 37/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6796 - loss: 0.9886 - val_accuracy: 0.6000 - val_loss: 1.1813\n",
      "Epoch 38/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5799 - loss: 1.1396 - val_accuracy: 0.6600 - val_loss: 1.0933\n",
      "Epoch 39/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5893 - loss: 1.0813 - val_accuracy: 0.6250 - val_loss: 1.1168\n",
      "Epoch 40/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5726 - loss: 1.0778 - val_accuracy: 0.6600 - val_loss: 0.9985\n",
      "Epoch 41/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5997 - loss: 1.1016 - val_accuracy: 0.6500 - val_loss: 1.0639\n",
      "Epoch 42/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6373 - loss: 1.0207 - val_accuracy: 0.6150 - val_loss: 1.1022\n",
      "Epoch 43/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5995 - loss: 1.0615 - val_accuracy: 0.6550 - val_loss: 1.0280\n",
      "Epoch 44/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6429 - loss: 1.0095 - val_accuracy: 0.6050 - val_loss: 1.1251\n",
      "Epoch 45/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6330 - loss: 1.0332 - val_accuracy: 0.6750 - val_loss: 1.0116\n",
      "Epoch 46/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6230 - loss: 1.0644 - val_accuracy: 0.6300 - val_loss: 1.0750\n",
      "Epoch 47/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6576 - loss: 0.9888 - val_accuracy: 0.6400 - val_loss: 1.0616\n",
      "Epoch 48/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6351 - loss: 0.9997 - val_accuracy: 0.6250 - val_loss: 1.1209\n",
      "Epoch 49/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5976 - loss: 1.0350 - val_accuracy: 0.6250 - val_loss: 1.1161\n",
      "Epoch 50/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6202 - loss: 1.0228 - val_accuracy: 0.6550 - val_loss: 1.0030\n",
      "Epoch 51/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6603 - loss: 0.9438 - val_accuracy: 0.6050 - val_loss: 1.1307\n",
      "Epoch 52/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6393 - loss: 0.9743 - val_accuracy: 0.6700 - val_loss: 1.0126\n",
      "Epoch 53/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6422 - loss: 1.0143 - val_accuracy: 0.6650 - val_loss: 1.0334\n",
      "Epoch 54/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6335 - loss: 1.0174 - val_accuracy: 0.6500 - val_loss: 1.0436\n",
      "Epoch 55/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6421 - loss: 0.9715 - val_accuracy: 0.6600 - val_loss: 1.0514\n",
      "Epoch 56/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6770 - loss: 0.8880 - val_accuracy: 0.6650 - val_loss: 1.0109\n",
      "Epoch 57/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6432 - loss: 0.9932 - val_accuracy: 0.6500 - val_loss: 1.0084\n",
      "Epoch 58/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6717 - loss: 0.8853 - val_accuracy: 0.6900 - val_loss: 0.9387\n",
      "Epoch 59/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6624 - loss: 0.9369 - val_accuracy: 0.6550 - val_loss: 1.1514\n",
      "Epoch 60/60\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7058 - loss: 0.8209 - val_accuracy: 0.6950 - val_loss: 0.9812\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dropout, Dense, BatchNormalization\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(20, 2)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hybrid_history = model.fit(X_train, y_train, epochs=60, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7552ca80-dec1-4e2f-8845-c43e0dfbc712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6900 - loss: 0.9780 \n",
      "CNN + LSTM Hybrid Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"CNN + LSTM Hybrid Accuracy: {test_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd82b979-5403-4a5c-a384-5c1d51911403",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Call the function with all four models\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m plot_model_history(\n\u001b[0;32m     33\u001b[0m     histories\u001b[38;5;241m=\u001b[39m[fcnn_history, cnn_history, lstm_history, hybrid_history],\n\u001b[0;32m     34\u001b[0m     names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFCNN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN+LSTM\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     35\u001b[0m )\n",
      "Cell \u001b[1;32mIn[20], line 9\u001b[0m, in \u001b[0;36mplot_model_history\u001b[1;34m(histories, names)\u001b[0m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m history, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(histories, names):\n\u001b[1;32m----> 9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Val\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Accuracy over Epochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'history'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_history(histories, names):\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for history, name in zip(histories, names):\n",
    "        plt.plot(history.history['accuracy'], label=f'{name} Train')\n",
    "        plt.plot(history.history['val_accuracy'], linestyle='--', label=f'{name} Val')\n",
    "    plt.title('Model Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for history, name in zip(histories, names):\n",
    "        plt.plot(history.history['loss'], label=f'{name} Train')\n",
    "        plt.plot(history.history['val_loss'], linestyle='--', label=f'{name} Val')\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with all four models\n",
    "plot_model_history(\n",
    "    histories=[fcnn_history, cnn_history, lstm_history, hybrid_history],\n",
    "    names=['FCNN', 'CNN', 'LSTM', 'CNN+LSTM']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe270a5-0cb9-41f0-8639-414bb7376e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_names = ['FCNN', 'CNN', 'LSTM', 'CNN+LSTM']\n",
    "accuracies = [0.44, 0.61, 0.55, 0.68]  # Replace with your actual test accuracies\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(model_names, accuracies, color=['gray', 'skyblue', 'orange', 'green'])\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Model Test Accuracy Comparison')\n",
    "\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.02, f'{acc:.2f}', ha='center', fontsize=12)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccc2d9c-00fb-4dfb-8b0a-25cde0fe38ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6881da86-f7cd-4ef8-ab41-8818222ad70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
